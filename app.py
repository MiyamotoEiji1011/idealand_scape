import streamlit as st
import nomic
from nomic import AtlasDataset
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import pandas as pd
from gspread_dataframe import set_with_dataframe

st.title("Nomic Atlas â†’ Google Sheets Sync Demo (Data Hold & Export)")

# =======================================
# 1ï¸âƒ£ Nomic Settings
# =======================================
st.subheader("ğŸ”‘ Nomic Connection Settings")

default_token = st.secrets.get("NOMIC_TOKEN", "")

token = st.text_input("API Token", value=default_token, type="password")
domain = st.text_input("Domain", value="atlas.nomic.ai")
map_name = st.text_input("Map Name", value="chizai-capcom-from-500")

map_data = None
df_metadata = None
df_topics = None
df_data = None

if st.button("Fetch Dataset"):
    if not token:
        st.error("âŒ Please provide API token first.")
    else:
        try:
            nomic.login(token=token, domain=domain)
            dataset = AtlasDataset(map_name)
            map_data = dataset.maps[0]

            # --- Hold Data ---
            df_metadata = map_data.topics.metadata
            df_topics = map_data.topics.df
            df_data = map_data.data.df

            st.success(f"âœ… Dataset fetched successfully! Metadata rows: {len(df_metadata)}, Topics rows: {len(df_topics)}, Data rows: {len(df_data)}")

        except Exception as e:
            st.error(f"âŒ Failed to fetch dataset: {e}")

# =======================================
# 2ï¸âƒ£ Google Sheets Settings
# =======================================
st.subheader("ğŸ“„ Google Sheets Settings")

spreadsheet_id = st.text_input(
    "Spreadsheet ID",
    value="1iPnaVVdUSC5BfNdxPVRSZAOiaCYWcMDYQWs5ps3AJsk"
)
worksheet_name = st.text_input("Worksheet Name", value="ã‚·ãƒ¼ãƒˆ1")

# Load service account credentials
try:
    service_account_info = json.loads(st.secrets["google_service_account"]["value"])
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(service_account_info, scope)
    client = gspread.authorize(creds)
    st.success("âœ… Google Service Account Loaded Successfully!")
except Exception as e:
    st.error(f"âŒ Failed to load service account: {e}")
    client = None

# =======================================
# 3ï¸âƒ£ Download CSVs for local backup
# =======================================
if map_data is not None:
    st.subheader("ğŸ’¾ Download Raw Data")
    if st.button("Download metadata CSV"):
        csv = df_metadata.to_csv(index=False)
        st.download_button("Download Metadata", csv, file_name="metadata.csv", mime="text/csv")
    if st.button("Download topics CSV"):
        csv = df_topics.to_csv(index=False)
        st.download_button("Download Topics", csv, file_name="topics.csv", mime="text/csv")
    if st.button("Download data CSV"):
        csv = df_data.to_csv(index=False)
        st.download_button("Download Data", csv, file_name="data.csv", mime="text/csv")

# =======================================
# 4ï¸âƒ£ Prepare empty DataFrame for Google Sheets
# =======================================
columns = [
    "depth", "topic_id", "Nomic Topic: Broad", "Nomic Topic: Medium", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
    "ã‚¢ã‚¤ãƒ‡ã‚¢æ•°", "å¹³å‡ã‚¹ã‚³ã‚¢", "æ–°è¦æ€§å¹³å‡ã‚¹ã‚³ã‚¢", "å¸‚å ´æ€§å¹³å‡ã‚¹ã‚³ã‚¢", "å®Ÿç¾æ€§å¹³å‡ã‚¹ã‚³ã‚¢",
    "å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢æ•°(12ç‚¹ä»¥ä¸Š)", "å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢ã®æ¯”ç‡(12ç‚¹ä»¥ä¸Š)",
    "novelty_score(æ–°è¦æ€§)å¹³å‡ã‚¹ã‚³ã‚¢", "novelty_score(æ–°è¦æ€§)å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢æ•°(4ç‚¹ä»¥ä¸Š)",
    "novelty_score(æ–°è¦æ€§)å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢æ¯”ç‡(4ç‚¹ä»¥ä¸Š)",
    "feasibility_score(å®Ÿç¾å¯èƒ½æ€§)å¹³å‡ã‚¹ã‚³ã‚¢", "feasibility_score(å®Ÿç¾å¯èƒ½æ€§)å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢æ•°(4ç‚¹ä»¥ä¸Š)",
    "feasibility_score(å®Ÿç¾å¯èƒ½æ€§)å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢æ¯”ç‡(4ç‚¹ä»¥ä¸Š)",
    "marketability_score(å¸‚å ´æ€§)å¹³å‡ã‚¹ã‚³ã‚¢", "marketability_score(å¸‚å ´æ€§)å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢æ•°(4ç‚¹ä»¥ä¸Š)",
    "marketability_score(å¸‚å ´æ€§)å„ªç§€ã‚¢ã‚¤ãƒ‡ã‚¢æ¯”ç‡(4ç‚¹ä»¥ä¸Š)",
    "ã‚¢ã‚¤ãƒ‡ã‚¢å", "Summary", "ã‚«ãƒ†ã‚´ãƒªãƒ¼", "åˆè¨ˆã‚¹ã‚³ã‚¢", "æ–°è¦æ€§ã‚¹ã‚³ã‚¢", "å¸‚å ´æ€§ã‚¹ã‚³ã‚¢", "å®Ÿç¾æ€§ã‚¹ã‚³ã‚¢"
]

df_master = pd.DataFrame(columns=columns)


